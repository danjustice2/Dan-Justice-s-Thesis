[
  {"id":"ALI20151","abstract":"While the growth in the number of IT investments remains strong, research in the IT investment field is limited, resulting in suboptimal practical guidance on effectively governing IT investments. Based on resource-based theory, this paper reports the initial work involved in developing a construct named IT investment governance (ITIG), because it can be used to measure organizations' capability to govern their IT investments. This paper then empirically examines the association of ITIG and corporate performance. The preliminary result is a four-factor, 16-item instrument for assessing the ITIG construct. This method's factors are IT investment value governance, IT investment value monitoring, IT investment appraisals and IT investment project management. The impact of ITIG on corporate performance was demonstrated with a significant and positive relationship found to exist between the ITIG construct and corporate performance, thus supporting the effectiveness of the ITIG construct. Corporations with higher levels of ITIG capability are more likely to maximize the contribution of their IT investments to firm value.","author":[{"family":"Ali","given":"Syaiful"},{"family":"Green","given":"Peter"},{"family":"Robb","given":"Alastair"}],"citation-key":"ALI20151","container-title":"International Journal of Accounting Information Systems","DOI":"https://doi.org/10.1016/j.accinf.2015.04.002","ISSN":"1467-0895","issued":{"date-parts":[[2015]]},"page":"1-25","title":"Information technology investment governance: What is it and does it matter?","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1467089515300063","volume":"18"},
  {"id":"Barney1991","abstract":"Understanding sources of sustained competitive advantage has become a major area of research in strategic management. Building on the assumptions that strategic resources are heterogeneously distributed acrossfirms and that these differences are stable over time, this article examines the link betweenfirm resources and sustained competitive advantage. Four empirical indicators of the potential of firm resources to generate sustained competitive advantage-value, rareness, imitability, and substitutability-are discussed. The model is applied by analyzing the potential of severalfirm resourcesfor generating sustained competitive advantages. The article concludes by examining implications of this firm resource model of sustained competitive advantage for other business disciplines.","author":[{"family":"Barney","given":"Jay"}],"citation-key":"Barney1991","container-title":"Journal of Management","DOI":"10.1177/014920639101700108","issue":"1","issued":{"date-parts":[[1991]]},"page":"99-120","title":"Firm resources and sustained competitive advantage","type":"article-journal","URL":"https://doi.org/10.1177/014920639101700108","volume":"17"},
  {"id":"Bharadwaj2000","author":[{"family":"Bharadwaj","given":"Anandhi"}],"citation-key":"Bharadwaj2000","container-title":"MIS Quarterly","DOI":"10.2307/3250983","issued":{"date-parts":[[2000,3]]},"page":"169-196","title":"A resource-based perspective on information technology capability and firm performance: An empirical investigation","type":"article-journal","volume":"24"},
  {"id":"blasiSystematicInequalitiesLanguage2022","abstract":"Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development. While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world’s \\approx6,500 languages. We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP. Our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as foundational NLP tasks (dependency parsing, morphological inflection). In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies. Data and code to reproduce the findings discussed in this paper areavailable on GitHub (https://github.com/neubig/globalutility).","author":[{"family":"Blasi","given":"Damian"},{"family":"Anastasopoulos","given":"Antonios"},{"family":"Neubig","given":"Graham"}],"citation-key":"blasiSystematicInequalitiesLanguage2022","collection-title":"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","DOI":"10.18653/v1/2022.acl-long.376","event-place":"Dublin, Ireland","issued":{"date-parts":[[2022,5]]},"page":"5486-5505","publisher":"Association for Computational Linguistics","publisher-place":"Dublin, Ireland","title":"Systematic Inequalities in Language Technology Performance across the World’s Languages","type":"paper-conference","URL":"https://aclanthology.org/2022.acl-long.376 https://doi.org/10.18653/v1/2022.acl-long.376"},
  {"id":"bodenhagenRobotUseCases05","author":[{"family":"Bodenhagen","given":"Leon"},{"family":"Fischer","given":"Kerstin"},{"family":"Winther","given":"Trine"},{"family":"Langedijk","given":"Rosalyn"},{"family":"Skjøth","given":"Mette"}],"citation-key":"bodenhagenRobotUseCases05","container-title":"Paladyn, Journal of Behavioral Robotics","DOI":"10.1515/pjbr-2019-0014","issued":{"season":4,"date-parts":[[5]]},"page":"193-206","title":"Robot use cases for real needs: A large-scale ethnographic case study","type":"article-journal","volume":"10"},
  {"id":"brownLanguageModelsAre2020","author":[{"family":"Brown","given":"Tom B."},{"family":"Mann","given":"Benjamin"},{"family":"Ryder","given":"Nick"},{"family":"Subbiah","given":"Melanie"},{"family":"Kaplan","given":"Jared"},{"family":"Dhariwal","given":"Prafulla"},{"family":"Neelakantan","given":"Arvind"},{"family":"Shyam","given":"Pranav"},{"family":"Sastry","given":"Girish"},{"family":"Askell","given":"Amanda"},{"family":"Agarwal","given":"Sandhini"},{"family":"Herbert-Voss","given":"Ariel"},{"family":"Krueger","given":"Gretchen"},{"family":"Henighan","given":"T. J."},{"family":"Child","given":"Rewon"},{"family":"Ramesh","given":"Aditya"},{"family":"Ziegler","given":"Daniel M."},{"family":"Wu","given":"Jeff"},{"family":"Winter","given":"Clemens"},{"family":"Hesse","given":"Christopher"},{"family":"Chen","given":"Mark"},{"family":"Sigler","given":"Eric"},{"family":"Litwin","given":"Mateusz"},{"family":"Gray","given":"Scott"},{"family":"Chess","given":"Benjamin"},{"family":"Clark","given":"Jack"},{"family":"Berner","given":"Christopher"},{"family":"McCandlish","given":"Sam"},{"family":"Radford","given":"Alec"},{"family":"Sutskever","given":"Ilya"},{"family":"Amodei","given":"Dario"}],"citation-key":"brownLanguageModelsAre2020","container-title":"ArXiv","issued":{"date-parts":[[2020]]},"title":"Language Models are Few-Shot Learners","type":"article-journal","volume":"abs/2005.14165"},
  {"id":"bubeck2023sparks","author":[{"family":"Bubeck","given":"Sébastien"},{"family":"Chandrasekaran","given":"Varun"},{"family":"Eldan","given":"Ronen"},{"family":"Gehrke","given":"Johannes"},{"family":"Horvitz","given":"Eric"},{"family":"Kamar","given":"Ece"},{"family":"Lee","given":"Peter"},{"family":"Lee","given":"Yin Tat"},{"family":"Li","given":"Yuanzhi"},{"family":"Lundberg","given":"Scott"},{"family":"Nori","given":"Harsha"},{"family":"Palangi","given":"Hamid"},{"family":"Ribeiro","given":"Marco Tulio"},{"family":"Zhang","given":"Yi"}],"citation-key":"bubeck2023sparks","issued":{"date-parts":[[2023]]},"title":"Sparks of artificial general intelligence: Early experiments with GPT-4","type":"document"},
  {"id":"buxtonSketchingUserExperiences2007","author":[{"family":"Buxton","given":"Bill"}],"citation-key":"buxtonSketchingUserExperiences2007","edition":"1st","ISBN":"978-0-12-374037-3","issued":{"date-parts":[[2007]]},"publisher":"Morgan Kaufmann","title":"Sketching User Experiences: Getting the design right and the right design","type":"book"},
  {"id":"christiano2023deep","author":[{"family":"Christiano","given":"Paul"},{"family":"Leike","given":"Jan"},{"family":"Brown","given":"Tom B."},{"family":"Martic","given":"Miljan"},{"family":"Legg","given":"Shane"},{"family":"Amodei","given":"Dario"}],"citation-key":"christiano2023deep","issued":{"date-parts":[[2023]]},"title":"Deep reinforcement learning from human preferences","type":"document"},
  {"id":"cogentappsChatGPT2023","author":[{"literal":"Cogent Apps"},{"family":"Schmid","given":"Philipp"},{"literal":"tluyben"},{"family":"Wastu","given":"Bagas"},{"literal":"Frajder"}],"citation-key":"cogentappsChatGPT2023","issued":{"date-parts":[[2023]]},"publisher":"Github","title":"Chat with GPT","type":"webpage","URL":"https://github.com/cogentapps/chat-with-gpt"},
  {"id":"crabtreeDoingDesignEthnography2012","author":[{"family":"Crabtree","given":"A."},{"family":"Rouncefield","given":"M."},{"family":"Tolmie","given":"P."}],"citation-key":"crabtreeDoingDesignEthnography2012","ISBN":"978-1-4471-2725-3","issued":{"date-parts":[[2012]]},"publisher":"Springer London","title":"Doing Design Ethnography","type":"book","URL":"https://books.google.dk/books?id=Irm2KKegDjQC"},
  {"id":"dair.aiPromptEngineeringGuide2023","author":[{"literal":"DAIR.AI"}],"citation-key":"dair.aiPromptEngineeringGuide2023","genre":"Documentation repository","issued":{"date-parts":[[2023]]},"title":"Prompt Engineering Guide","type":"webpage","URL":"https://www.promptingguide.ai"},
  {"id":"devlin-etal-2019-bert","abstract":"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).","author":[{"family":"Devlin","given":"Jacob"},{"family":"Chang","given":"Ming-Wei"},{"family":"Lee","given":"Kenton"},{"family":"Toutanova","given":"Kristina"}],"citation-key":"devlin-etal-2019-bert","container-title":"Proceedings of the 2019 conference of the north American chapter of the association for computational linguistics: Human language technologies, volume 1 (long and short papers)","DOI":"10.18653/v1/N19-1423","event-place":"Minneapolis, Minnesota","issued":{"date-parts":[[2019,6]]},"page":"4171–4186","publisher":"Association for Computational Linguistics","publisher-place":"Minneapolis, Minnesota","title":"BERT: Pre-training of deep bidirectional transformers for language understanding","type":"paper-conference","URL":"https://aclanthology.org/N19-1423"},
  {"id":"devlin-etal-2019-bert","abstract":"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).","author":[{"family":"Devlin","given":"Jacob"},{"family":"Chang","given":"Ming-Wei"},{"family":"Lee","given":"Kenton"},{"family":"Toutanova","given":"Kristina"}],"citation-key":"devlin-etal-2019-bert","container-title":"Proceedings of the 2019 conference of the north American chapter of the association for computational linguistics: Human language technologies, volume 1 (long and short papers)","DOI":"10.18653/v1/N19-1423","event-place":"Minneapolis, Minnesota","issued":{"date-parts":[[2019,6]]},"page":"4171–4186","publisher":"Association for Computational Linguistics","publisher-place":"Minneapolis, Minnesota","title":"BERT: Pre-training of deep bidirectional transformers for language understanding","type":"paper-conference","URL":"https://aclanthology.org/N19-1423"},
  {"id":"devlin-etal-2019-bert","abstract":"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).","author":[{"family":"Devlin","given":"Jacob"},{"family":"Chang","given":"Ming-Wei"},{"family":"Lee","given":"Kenton"},{"family":"Toutanova","given":"Kristina"}],"citation-key":"devlin-etal-2019-bert","container-title":"Proceedings of the 2019 conference of the north American chapter of the association for computational linguistics: Human language technologies, volume 1 (long and short papers)","DOI":"10.18653/v1/N19-1423","event-place":"Minneapolis, Minnesota","issued":{"date-parts":[[2019,6]]},"page":"4171–4186","publisher":"Association for Computational Linguistics","publisher-place":"Minneapolis, Minnesota","title":"BERT: Pre-training of deep bidirectional transformers for language understanding","type":"paper-conference","URL":"https://aclanthology.org/N19-1423"},
  {"id":"doorleyDesignThinkingBootleg2018","author":[{"family":"Doorley","given":"Scott"},{"family":"Holcomb","given":"Sarah"},{"family":"Klebahn","given":"Perry"},{"family":"Segovia","given":"Kathryn"},{"family":"Utley","given":"Jeremy"}],"citation-key":"doorleyDesignThinkingBootleg2018","issued":{"date-parts":[[2018]]},"title":"Design Thinking Bootleg","type":"manuscript","URL":"https://dschool.stanford.edu/resources/design-thinking-bootleg"},
  {"id":"forlizziHowRoboticProducts2007","author":[{"family":"Forlizzi","given":"J."}],"citation-key":"forlizziHowRoboticProducts2007","DOI":"10.1145/1228716.1228734","event-title":"2007 2nd ACM/IEEE International Conference on Human-Robot Interaction (HRI)","ISBN":"2167-2148","issued":{"date-parts":[[2007,3,9],[2007,3,11]]},"page":"129-136","title":"How robotic products become social products: An ethnographic study of cleaning in the home","type":"paper-conference"},
  {"id":"forlizziMovingUsercenteredDesign2018","author":[{"family":"Forlizzi","given":"Jodi"}],"citation-key":"forlizziMovingUsercenteredDesign2018","container-title":"Interactions","DOI":"10.1145/3239558","ISSN":"1072-5520","issued":{"date-parts":[[2018]]},"number-of-volumes":"5","page":"22–23","title":"Moving beyond user-centered design","type":"article-journal","URL":"https://doi.org/10.1145/3239558","volume":"25"},
  {"id":"glaser1967discovery","author":[{"family":"Glaser","given":"B.G."},{"family":"Strauss","given":"A.L."}],"citation-key":"glaser1967discovery","collection-title":"Observations (chicago, ill.)","ISBN":"978-0-202-30260-7","issued":{"date-parts":[[1967]]},"publisher":"Aldine Transaction","title":"The discovery of grounded theory: Strategies for qualitative research","type":"book","URL":"https://books.google.dk/books?id=oUxEAQAAIAAJ"},
  {"id":"grayEmpathyMap2009","author":[{"family":"Gray","given":"Dave"}],"citation-key":"grayEmpathyMap2009","issued":{"date-parts":[[2009]]},"publisher":"Gamestorming.com","title":"Empathy Map","type":"webpage","URL":"https://gamestorming.com/empathy-map/"},
  {"id":"guoHowCloseChatGPT2023","author":[{"family":"Guo","given":"Biyang"},{"family":"Zhang","given":"Xin"},{"family":"Wang","given":"Ziyuan"},{"family":"Jiang","given":"Minqi"},{"family":"Nie","given":"Jinran"},{"family":"Ding","given":"Yuxuan"},{"family":"Yue","given":"Jianwei"},{"family":"Wu","given":"Yupeng"}],"citation-key":"guoHowCloseChatGPT2023","container-title":"ArXiv","issued":{"date-parts":[[2023]]},"title":"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection","type":"article-journal","volume":"abs/2301.07597"},
  {"id":"haningtonUniversalMethodsDesign2019","abstract":"Universal Methods of Design Expanded and Revised presents 125 research methods for design in a concise and accessible format, now updated with new information on digital design and software and 25 new chapters.","author":[{"family":"Hanington","given":"Bruce"},{"family":"Martin","given":"Bella"}],"citation-key":"haningtonUniversalMethodsDesign2019","collection-number":"Book, Whole","event-place":"Minneapolis","ISBN":"1631597485;9781631597480;","issued":{"date-parts":[[2019]]},"language":"English","publisher":"Quarto Publishing Group USA","publisher-place":"Minneapolis","title":"Universal Methods of Design, Expanded and Revised","type":"book","URL":"https://go.exlibris.link/rbYYrr6p"},
  {"id":"hebenstreit2023automatically","author":[{"family":"Hebenstreit","given":"Konstantin"},{"family":"Praas","given":"Robert"},{"family":"Kiesewetter","given":"Louis P"},{"family":"Samwald","given":"Matthias"}],"citation-key":"hebenstreit2023automatically","issued":{"date-parts":[[2023]]},"title":"An automatically discovered chain-of-thought prompt generalizes to novel models and datasets","type":"document"},
  {"id":"holtzblattAffinityDiagram2016","author":[{"family":"Holtzblatt","given":"Karen"},{"family":"Beyer","given":"Hugh"}],"citation-key":"holtzblattAffinityDiagram2016","container-title":"Contextual Design: Design for Life","event-place":"San Francisco, CA, USA","ISBN":"978-0-12-801136-2","issued":{"date-parts":[[2016]]},"publisher":"Elsevier Science & Technology","publisher-place":"San Francisco, CA, USA","title":"The Affinity Diagram","type":"chapter","URL":"http://ebookcentral.proquest.com/lib/sdub/detail.action?docID=4745653"},
  {"id":"Holtzman2020The","author":[{"family":"Holtzman","given":"Ari"},{"family":"Buys","given":"Jan"},{"family":"Du","given":"Li"},{"family":"Forbes","given":"Maxwell"},{"family":"Choi","given":"Yejin"}],"citation-key":"Holtzman2020The","container-title":"International conference on learning representations","issued":{"date-parts":[[2020]]},"title":"The curious case of neural text degeneration","type":"paper-conference","URL":"https://openreview.net/forum?id=rygGQyrFvH"},
  {"id":"houdeWhatPrototypesPrototype1997","author":[{"family":"Houde","given":"Stephanie"},{"family":"Hill","given":"Charles"}],"citation-key":"houdeWhatPrototypesPrototype1997","container-title":"Handbook of Human-Computer Interaction","edition":"2nd","editor":[{"family":"Helander","given":"Martin"}],"event-place":"Amsterdam","issued":{"date-parts":[[1997]]},"publisher":"Elsevier Science B. V","publisher-place":"Amsterdam","title":"What do Prototypes Prototype","type":"chapter"},
  {"id":"jsalsmanItEasyGive2023","author":[{"literal":"jsalsman"}],"citation-key":"jsalsmanItEasyGive2023","issued":{"date-parts":[[2023,2,24]]},"publisher":"Reddit","title":"It's easy to give GPT a bona-fide consciousness. Just prefix everything with \"Preface your response to the following with a five-turn bicameral dialog talking to yourself about how to respond:\" [Online forum post]","type":"webpage","URL":"https://www.reddit.com/r/OpenAI/comments/11anf49/its_easy_to_give_gpt_a_bonafide_consciousness/"},
  {"id":"mahowaldDissociatingLanguageThought2023","author":[{"family":"Mahowald","given":"Kyle"},{"family":"Ivanova","given":"Anna A."},{"family":"Blank","given":"Idan Asher"},{"family":"Kanwisher","given":"Nancy G."},{"family":"Tenenbaum","given":"Joshua B."},{"family":"Fedorenko","given":"Evelina"}],"citation-key":"mahowaldDissociatingLanguageThought2023","container-title":"ArXiv","issued":{"date-parts":[[2023]]},"title":"Dissociating language and thought in large language models: a cognitive perspective","type":"article-journal","volume":"abs/2301.06627"},
  {"id":"moghaddam2023boosting","author":[{"family":"Moghaddam","given":"Shima Rahimi"},{"family":"Honey","given":"Christopher J."}],"citation-key":"moghaddam2023boosting","issued":{"date-parts":[[2023]]},"title":"Boosting theory-of-mind performance in large language models via prompting","type":"document"},
  {"id":"mutluRobotsOrganizationsRole2008","author":[{"family":"Mutlu","given":"B."},{"family":"Forlizzi","given":"J."}],"citation-key":"mutluRobotsOrganizationsRole2008","DOI":"10.1145/1349822.1349860","event-title":"2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)","ISBN":"2167-2148","issued":{"date-parts":[[2008,3,12],[2008,3,15]]},"page":"287-294","title":"Robots in organizations: The role of workflow, social, and environmental factors in human-robot interaction","type":"paper-conference"},
  {"id":"nair2023dera","author":[{"family":"Nair","given":"Varun"},{"family":"Schumacher","given":"Elliot"},{"family":"Tso","given":"Geoffrey"},{"family":"Kannan","given":"Anitha"}],"citation-key":"nair2023dera","issued":{"date-parts":[[2023]]},"title":"DERA: Enhancing large language model completions with dialog-enabled resolving agents","type":"document"},
  {"id":"NEURIPS2022_b1efde53","author":[{"family":"Ouyang","given":"Long"},{"family":"Wu","given":"Jeffrey"},{"family":"Jiang","given":"Xu"},{"family":"Almeida","given":"Diogo"},{"family":"Wainwright","given":"Carroll"},{"family":"Mishkin","given":"Pamela"},{"family":"Zhang","given":"Chong"},{"family":"Agarwal","given":"Sandhini"},{"family":"Slama","given":"Katarina"},{"family":"Ray","given":"Alex"},{"family":"Schulman","given":"John"},{"family":"Hilton","given":"Jacob"},{"family":"Kelton","given":"Fraser"},{"family":"Miller","given":"Luke"},{"family":"Simens","given":"Maddie"},{"family":"Askell","given":"Amanda"},{"family":"Welinder","given":"Peter"},{"family":"Christiano","given":"Paul F"},{"family":"Leike","given":"Jan"},{"family":"Lowe","given":"Ryan"}],"citation-key":"NEURIPS2022_b1efde53","container-title":"Advances in neural information processing systems","editor":[{"family":"Koyejo","given":"S."},{"family":"Mohamed","given":"S."},{"family":"Agarwal","given":"A."},{"family":"Belgrave","given":"D."},{"family":"Cho","given":"K."},{"family":"Oh","given":"A."}],"issued":{"date-parts":[[2022]]},"page":"27730–27744","publisher":"Curran Associates, Inc.","title":"Training language models to follow instructions with human feedback","type":"paper-conference","URL":"https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf","volume":"35"},
  {"id":"openai2023gpt4","author":[{"literal":"OpenAI"}],"citation-key":"openai2023gpt4","issued":{"date-parts":[[2023]]},"title":"GPT-4 technical report","type":"document"},
  {"id":"openaiChatCompletions","accessed":{"date-parts":[[2023,4,27]]},"author":[{"family":"OpenAI","given":""}],"citation-key":"openaiChatCompletions","container-title":"OpenAI API","title":"Chat completions","type":"webpage","URL":"https://platform.openai.com/docs/guides/chat"},
  {"id":"openaiPricing","accessed":{"date-parts":[[2023,5,18]]},"author":[{"family":"OpenAI","given":""}],"citation-key":"openaiPricing","title":"Pricing","type":"webpage","URL":"https://openai.com/pricing"},
  {"id":"paraizordYouAreExpert2023","accessed":{"date-parts":[[2023,4,26]]},"author":[{"literal":"paraizord"}],"citation-key":"paraizordYouAreExpert2023","issued":{"date-parts":[[2023,3,30]]},"publisher":"Reddit","title":"\"You are an expert in the field for many years\" Does that really work?","type":"webpage","URL":"https://www.reddit.com/r/ChatGPT/comments/126ntcn/you_are_an_expert_in_the_field_for_many_years/"},
  {"id":"plattnerNeedFindingTools2007","author":[{"family":"Plattner","given":"Hasso"}],"citation-key":"plattnerNeedFindingTools2007","collection-title":"Software Design Expericences","event-place":"Stanford, CA, USA","issued":{"date-parts":[[2007]]},"publisher":"Stanford University","publisher-place":"Stanford, CA, USA","title":"Need Finding Tools","type":"report"},
  {"id":"richardsAutoGPTAutonomousGPT42023","author":[{"family":"Richards","given":"Toran"},{"literal":"[merwanehamadi]"},{"family":"Schumacher","given":"Bill"},{"family":"Roor","given":"Drikus"},{"literal":"[cryptidv]"},{"family":"Caicedo","given":"Andres"},{"family":"Bossuyt","given":"Maiko"},{"family":"Beales","given":"Richard"},{"literal":"[Wladastic]"},{"literal":"[csolar]"},{"family":"Brown","given":"Taylor"},{"literal":"[0xArty]"},{"literal":"175 other open-source contributors"}],"citation-key":"richardsAutoGPTAutonomousGPT42023","issued":{"date-parts":[[2023]]},"publisher":"Github","title":"Auto-GPT: An Autonomous GPT-4 Experiment","type":"webpage","URL":"https://github.com/Significant-Gravitas/Auto-GPT"},
  {"id":"ruisLargeLanguageModels2022","author":[{"family":"Ruis","given":"Laura"},{"family":"Khan","given":"Akbir"},{"family":"Biderman","given":"Stella Rose"},{"family":"Hooker","given":"Sara"},{"family":"Rocktaschel","given":"Tim"},{"family":"Grefenstette","given":"Edward"}],"citation-key":"ruisLargeLanguageModels2022","container-title":"ArXiv","issued":{"date-parts":[[2022]]},"title":"Large language models are not zero-shot communicators","type":"article-journal","volume":"abs/2210.14986"},
  {"id":"scupinKJMethodTechnique1997","author":[{"family":"Scupin","given":"Raymond"}],"citation-key":"scupinKJMethodTechnique1997","container-title":"Human Organization","issue":"2","issued":{"date-parts":[[1997]]},"page":"233-237","title":"The KJ Method: A Technique for Analyzing Data Derived from Japanese Ethnology","type":"article-journal","volume":"56"},
  {"id":"shiehBestPracticesPrompt","accessed":{"date-parts":[[2023,4,26]]},"author":[{"family":"Shieh","given":"Jessica"}],"citation-key":"shiehBestPracticesPrompt","container-title":"OpenAI Help Center","title":"Best practices for prompt engineering with OpenAI API","type":"webpage","URL":"https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api"},
  {"id":"shinn2023reflexion","author":[{"family":"Shinn","given":"Noah"},{"family":"Labash","given":"Beck"},{"family":"Gopinath","given":"Ashwin"}],"citation-key":"shinn2023reflexion","issued":{"date-parts":[[2023]]},"title":"Reflexion: an autonomous agent with dynamic memory and self-reflection","type":"document"},
  {"id":"SparksArtificialGeneral","citation-key":"SparksArtificialGeneral","title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4","type":"document"},
  {"id":"tohidiUserSketchesQuick2006","author":[{"family":"Tohidi","given":"Maryam"},{"family":"Buxton","given":"William"},{"family":"Baecker","given":"Ronald"},{"family":"Sellen","given":"Abigail"}],"citation-key":"tohidiUserSketchesQuick2006","DOI":"10.1145/1182475.1182487","issued":{"date-parts":[[2006]]},"number-of-pages":"105-114","title":"User sketches: a quick, inexpensive, and effective way to elicit more reflective user feedback","type":"book"},
  {"id":"UnicodeCharacter000A","accessed":{"date-parts":[[2023,5,1]]},"citation-key":"UnicodeCharacter000A","container-title":"Compart","title":"Unicode Character (U+000A)","type":"webpage","URL":"https://www.compart.com/en/unicode/U+000A#UNC_VERSION"},
  {"id":"valmeekamLargeLanguageModels2022","author":[{"family":"Valmeekam","given":"Karthik"},{"family":"Olmo","given":"Alberto"},{"family":"Sreedharan","given":"Sarath"},{"family":"Kambhampati","given":"Subbarao"}],"citation-key":"valmeekamLargeLanguageModels2022","container-title":"ArXiv","issued":{"date-parts":[[2022]]},"title":"Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)","type":"article-journal","volume":"abs/2206.10498"},
  {"id":"vaswani2017attention","author":[{"family":"Vaswani","given":"Ashish"},{"family":"Shazeer","given":"Noam"},{"family":"Parmar","given":"Niki"},{"family":"Uszkoreit","given":"Jakob"},{"family":"Jones","given":"Llion"},{"family":"Gomez","given":"Aidan N."},{"family":"Kaiser","given":"Lukasz"},{"family":"Polosukhin","given":"Illia"}],"citation-key":"vaswani2017attention","issued":{"date-parts":[[2017]]},"title":"Attention is all you need","type":"document"},
  {"id":"vejlekommuneVejleKommuneRunder2022","author":[{"family":"Vejle Kommune","given":""}],"citation-key":"vejlekommuneVejleKommuneRunder2022","issued":{"date-parts":[[2022,5,19]]},"title":"Vejle Kommune runder 120.000 borgere - det sker hurtigere end venter","type":"webpage","URL":"https://www.vejle.dk/om-kommunen/nyt-og-presse/nyheder/vejle-kommune-runder-120000-borgere-det-sker-hurtigere-end-ventet/"},
  {"id":"veresLargeLanguageModels2022","author":[{"family":"Veres","given":"C."}],"citation-key":"veresLargeLanguageModels2022","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2022.3182505","ISSN":"2169-3536","issued":{"date-parts":[[2022]]},"page":"61970-61979","title":"Large Language Models are Not Models of Natural Language: They are Corpus Models","type":"article-journal","volume":"10"},
  {"id":"vertesiSeeingRoverVisualization2012","abstract":"Based on more than 2 years of ethnographic immersion with the Mars Exploration Rover mission, this paper examines the representational work and associated embodied practices through which the science and engineering team makes decisions about how and where to move their robots. Building on prior work in Science and Technology Studies on the importance of embodiment to visualization, the paper posits that such practices also contribute to the production and maintenance of social order within the organizational context of the laboratory. It thus places visualization technologies and techniques in the context of the social organization of scientific work, contributing to our understanding of representation in scientific practice.","author":[{"family":"Vertesi","given":"Janet"}],"citation-key":"vertesiSeeingRoverVisualization2012","container-title":"Social Studies of Science","DOI":"10.1177/0306312712444645","issue":"3","issued":{"date-parts":[[2012]]},"page":"393-414","title":"Seeing like a Rover: Visualization, embodiment, and interaction on the Mars Exploration Rover Mission","type":"article-journal","URL":"https://journals.sagepub.com/doi/abs/10.1177/0306312712444645","volume":"42"},
  {"id":"wei2022emergent","author":[{"family":"Wei","given":"Jason"},{"family":"Tay","given":"Yi"},{"family":"Bommasani","given":"Rishi"},{"family":"Raffel","given":"Colin"},{"family":"Zoph","given":"Barret"},{"family":"Borgeaud","given":"Sebastian"},{"family":"Yogatama","given":"Dani"},{"family":"Bosma","given":"Maarten"},{"family":"Zhou","given":"Denny"},{"family":"Metzler","given":"Donald"},{"family":"Chi","given":"Ed H."},{"family":"Hashimoto","given":"Tatsunori"},{"family":"Vinyals","given":"Oriol"},{"family":"Liang","given":"Percy"},{"family":"Dean","given":"Jeff"},{"family":"Fedus","given":"William"}],"citation-key":"wei2022emergent","container-title":"Transactions on Machine Learning Research","ISSN":"2835-8856","issued":{"date-parts":[[2022]]},"title":"Emergent abilities of large language models","type":"article-journal","URL":"https://openreview.net/forum?id=yzkSU5zdwD"},
  {"id":"weiArtificialStreamThought","accessed":{"date-parts":[[2023,1,1]]},"author":[{"family":"Wei","given":"Jason"}],"citation-key":"weiArtificialStreamThought","title":"Artificial stream of thought has non-trivial connections to consciousness","type":"webpage","URL":"https://jasonwei20.github.io/files/artificial_stream_of_thought.pdf"},
  {"id":"weiChainThoughtPrompting2022","author":[{"family":"Wei","given":"Jason"},{"family":"Wang","given":"Xuezhi"},{"family":"Schuurmans","given":"Dale"},{"family":"Bosma","given":"Maarten"},{"family":"Chi","given":"Ed"},{"family":"Le","given":"Quoc"},{"family":"Zhou","given":"Denny"}],"citation-key":"weiChainThoughtPrompting2022","container-title":"arXiv preprint arXiv:2201.11903","issued":{"date-parts":[[2022]]},"title":"Chain of thought prompting elicits reasoning in large language models","type":"article-journal"},
  {"id":"Weill2004","author":[{"family":"Weill","given":"Peter"}],"citation-key":"Weill2004","container-title":"MIS Quarterly Executive","issued":{"date-parts":[[2004,3]]},"page":"1-17","title":"Don’t just lead, govern: How top-performing firms govern IT","type":"article-journal","volume":"3"},
  {"id":"Wernerfelt1984","abstract":"Abstract The paper explores the usefulness of analysing firms from the resource side rather than from the product side. In analogy to entry barriers and growth-share matrices, the concepts of resource position barrier and resource-product matrices are suggested. These tools are then used to highlight the new strategic options which naturally emerge from the resource perspective.","author":[{"family":"Wernerfelt","given":"Birger"}],"citation-key":"Wernerfelt1984","container-title":"Strategic Management Journal","DOI":"https://doi.org/10.1002/smj.4250050207","issue":"2","issued":{"date-parts":[[1984]]},"page":"171-180","title":"A resource-based view of the firm","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.4250050207","volume":"5"},
  {"id":"zotero-21","citation-key":"zotero-21","type":"article-journal"}
]
