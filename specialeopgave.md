# Navigating the Currents of Change: An Ethnographic Study of IT Investment Reporting in Organisations

Danny Ray Justice (02.03.00)
University of Southern Denmark
Department of Humanities
31st May, 2023

## Abstract

Abstract abstract

*Keywords:* Keyword

## Contents


## Introduction

Introduction text

### Problem Statement

The IT department at Vejle municipality has established an IT investment process that outlines a set of procedures for procuring new IT systems, software, and equipment. Despite these guidelines, employees do not always follow this process, leading to potential inefficiencies and discrepancies in IT investments. This study aims to explore the reasons why employees do not comply with the IT investment process and suggest strategies to improve compliance.

Additionally, the study seeks to evaluate the utility of OpenAI's family of large language models, Generative Pre-trained Transformer (also known as GPT), as a complementary tool to traditional research methods in understanding employees\' attitudes and behaviours towards the IT investment process. By comparing insights generated by these models with those obtained from traditional research methods, the study aims to determine the potential and limitations of using large language models as a qualitative research tool in ethnographic studies.

## Literature Review

### Ethnographic Methods (Crabtree et al. 2012)

#### Interview

Crabtree et al. (2012) advise that researchers treat interviews with caution. They suggest that interviews should be conducted in the actual flow of work as it unfolds and as the situation permits. They warn that what people say they do and what they actually do are not the same. It is not that people are lying, but that the accounts they offer in an interview often gloss over their work. The best way to conduct an interview is to be concerned with the just what and just how of the work, and not be driven by a pre-formulated schedule of questions removed from the actual doing of the work.

#### Field notes

According to Crabtree et al. (2012), making field notes is an essential part of fieldwork. It allows the researcher to document the things they see and hear and jot down their thoughts on the setting and its work. Field notes provide a record of what the researcher observes, hears, and is told. Keeping a good set of field notes helps researchers keep track of what they are being told and organize their thoughts. It is an active process that makes the researcher attend to the work as it occurs, helping them develop vulgar competence in it.

Crabtree et al. (2012) suggest that the notebook need not be a loose collection of disjointed comments. Researchers may use their notebook to structure their thoughts and develop a coherent account of the work of a setting. They recommend æ researchers make diagrams of the ecology of work to frame their inquiries into the work of a setting and represent it to others. Draw plans of the environment, indicate the people who inhabit it, their roles or responsibilities, and the artifacts that they use in doing the work. This helps researchers develop a detailed understanding of the setting\'s work and the methods members use to organize it as a real-world, real-time social accomplishment.

#### Formal Organisation of Work and Flow of Work

Crabtree et al. (2012) suggest that researchers describe how the setting\'s work is \'formally organised\' across a division of labour and how it is \'formally organised\' at an individual level. This includes plans, procedures, processes, and routines that the setting\'s members invoke to account for the organisation of their work. Researchers should also focus on the flow of work, which starts somewhere, with someone doing something and proceeds to some end. They should focus on how the work moves across individuals, how it flows from one activity to another and one person to another.

#### Discrete Sequences of Interactional Work and Cooperation and Collaboration

Crabtree et al. (2012) recommend that researchers flesh out their description of the flow of work by focusing on the discrete sequences of interactional work that are involved in the accomplishment of particular activities. Researchers should describe what is being done, who is doing it, and how the work is accomplished. Researchers should also focus on the cooperation and collaboration that takes place between people in the accomplishment of discrete sequences of interactional work. They should describe who is talking to whom, what they are talking about, what they do together, the transactions that take place between them, the hand-over of tasks, and what others do in response.

### Sketching (Buxton, 2007)

In \"Sketching User Experiences,\" Buxton (2007) emphasizes the importance of sketching for generating and exploring ideas in the design process. Sketching allows designers to quickly generate and iterate on ideas, explore different design possibilities, and ultimately arrive at a solution that best meets user needs.

Buxton provides numerous techniques and tools for using sketching to support idea generation, including sketching with pen and paper, creating paper prototypes, and storyboarding. He also emphasizes the importance of using sketching to support user-centered design, and provides practical advice on involving users in the design process and using sketching to elicit and communicate user requirements.

One of the strengths of the book is the practical advice it provides on how to use sketching for idea generation. Buxton emphasizes the importance of sketching as a means of exploring and refining ideas, and provides numerous examples of how sketching can be used to generate and communicate design concepts (Buxton, 2007). He also provides advice on how to use sketching to support different design activities, such as brainstorming, ideation, and prototyping (Buxton, 2007).

Another strength of the book is the emphasis on using sketching as a collaborative tool. Buxton highlights the value of sketching as a means of communicating and refining ideas with other stakeholders, such as team members, clients, and users. He provides advice on how to use sketches to facilitate communication and collaboration, and how to document and organize sketches for future reference (Buxton, 2007).

### Affinity Diagrams

Affinity diagrams, also known as the KJ method or affinity charting, were first developed by Japanese anthropologist Jiro Kawakita (as cited in Scupin, 1997). The method has since become widely adopted in various fields, including ethnographic user experience (UX) studies. Affinity diagrams are used to synthesise and categorise large amounts of qualitative data, such as observations, interviews, and field notes, into meaningful and easily understandable themes and patterns (Hanington & Martin, 2019).

The affinity diagramming process typically starts with the raw data being transformed into discrete statements or observations. These statements are then grouped based on their similarities and relationships (Hanington & Martin, 2019). The groups are subsequently labeled with descriptive headings, which capture the essence of their content. This iterative process allows for the identification of patterns, themes, and relationships among the collected data, thus providing insights and guidance for further analysis and design (Holtzblatt & Beyer, 2016).

In the context of ethnographic UX studies, affinity diagrams serve as a valuable tool for making sense of the complex and often messy data that emerges from immersive fieldwork (Holtzblatt & Beyer, 2016). By organising and categorising data in a structured manner, researchers can identify user needs, behaviours, and pain points, which can inform design decisions and enhance the overall user experience (Hanington & Martin, 2019).

Furthermore, affinity diagrams facilitate collaboration and interdisciplinary communication among research team members (Holtzblatt & Beyer, 2016). By engaging in the process of grouping and labeling data, researchers from different backgrounds and expertise can contribute to a shared understanding of the user experience, leading to more innovative and effective solutions.

## Methodology

### Elicit Research Assistant

In addition to traditional literature search methods, I used Elicit, a digital research assistant employing large language models. The steps followed while using Elicit in this study are outlined below:

Posing a Research Question: A research question was entered into Elicit (e.g., \"What are the ethical implications of using LLMs in qualitative research?\").

Semantic Similarity Searches: Elicit searched for relevant papers based on semantic relationships rather than just keyword matching, broadening the scope of literature found.

Custom Abstract Summaries: Elicit generated tailored summaries of the sources' abstracts, presenting only information relevant to the research question, thus providing an initial understanding and evaluation of the research.

Citation Graph Analysis: Elicit was used to explore the citation graph of selected papers to identify additional relevant literature based on citation relationships.

By following these steps and incorporating Elicit\'s features into the literature review process, a comprehensive and organised analysis of the available literature was achieved. Elicit served as a valuable resource in the development of the present study, contributing significantly to the literature review component.

### Ethnography

#### Semi-structured Interviews

To build empathy with the users, I conducted semi-structured interviews in an informal manner. Ideally, the interviews would have been conducted in the flow of work (Crabtree et al. 2012), but since new IT investments were not a regular part of most employees\' daily work outside of the IT department, it was not feasible to talk with employees in the midst of making new investments. Thus, the interviews were done in a \"decontextualised\" fashion.

In total, 12 employees were interviewed, selected based on a list of contacts provided by the author\'s contact person in Vejle's IT department. The list included decision-makers from all six administrations of the municipality. All employees on the list were assigned a number by which they were identified in my notes, never using their true names.

All but one of the interviews were conducted face-to-face, the remaining interview being held by video call in order to accommodate the participant, and notes were taken by hand in a notebook to maintain a relaxed atmosphere, as opposed to using audio and/or video recordings. The questions were not pre-formulated but were based loosely on an interview guide, allowing for a more natural and authentic conversation. During the interviews, brief notes were taken, and more detailed notes (Appendix X) were written as soon as possible afterward to ensure accuracy and facilitate data analysis.

#### Field Notes

In conducting my research, I recognised the significance of field notes as an essential tool for documenting and organising the vast amount of information that I would encounter during my fieldwork. As Crabtree et al. (2012) emphasise, field notes play a critical role in capturing the observations, thoughts, and reflections of the researcher on the setting under study. They offer a means to document the unfolding of work and provide a detailed record of the interactions, activities, and processes that shape the context of the research.

To ensure that I was able to keep an accurate and detailed account of my observations, I maintained a dedicated notebook where I recorded my thoughts, sketches, and other details of my fieldwork in Vejle. This notebook was, in particular, used to document the interviews conducted, avoiding the presence of laptop or tablet screens and recording devices, which I feared would disturb the natural flow of conversation.

In addition to traditional field notes, I also created a folder on a cloud-synced notes app that allowed me to make digital notes on my computer, smartphone, and tablet. This proved to be a valuable resource when I didn't have my physical notebook with me or when I was in the mood to type rather than write, allowing me to capture my thoughts and insights in a way that was convenient and flexible for my needs.

My field notes were instrumental in facilitating my understanding of the work in Vejle by highlighting areas of cooperation and collaboration between individuals that were not necessarily captured by the formal organisation of work. They provided a valuable means to document the handover of tasks and the transactions that took place between individuals, which helped to reveal the dynamic nature of the work.

In addition to being a useful record of my observations, my field notes served also as an active process of reflection, helping me create a mental model of the work being done in Vejle. By continually reflecting on what I was seeing and hearing, I was able to develop a detailed understanding of the setting\'s work and to refine my description of it over time. Furthermore, my field notes proved to be an invaluable resource for continually reworking my understanding of the work and for confirming or correcting my observations with those who were actually doing the work.

On the whole, my field notes served as a critical resource for documenting and organising the rich and complex data that I collected during my fieldwork. By capturing the unfolding of work in Vejle and facilitating my understanding of it, my field notes provided a solid foundation for the analysis and interpretation of my research findings.

### Large Language Models

In light of the limited literature on the application of LLMs, such as GPT-3.5 (from the ChatGPT platform) and GPT-4, in qualitative research, this study adopted an exploratory approach to investigate the potential of these tools. Consequently, I utilized these LLMs as supplementary instruments within this study. To maintain a clear and coherent narrative, I will discuss the reasoning and approach behind incorporating these tools in the upcoming sections. Additionally, for complete transparency, I have included the full transcripts of my interactions with the models in Appendix X.

#### Chat Functionality

The conversational capability of these LLMs provided me with a unique opportunity to gather information beyond my personal knowledge and the resources available in the context of my research. With their extensive corpus of text, LLMs are capable of generating responses to my questions that often offered fresh perspectives on my research topic, prompting me to consider new questions and viewpoints, and explore new avenues of inquiry that would have otherwise gone unexplored.

The LLMs not only gave me an advisor who was always available and never tired or impatient, but also encouraged me to think more creatively about my research and consider possibilities I may have overlooked.

As researchers in the humanities, we are well-acquainted with the ways human biases can shape and impact our understanding of the world. Similarly, LLMs can be biased by their training data. It is therefore particularly important for us to examine the potential biases and limitations of LLMs. By investigating the use of LLMs in our field, we can not only understand the potential limitations of these tools, but also find ways to mitigate any biases and make the most of their potential. Thus, it is essential for humanities researchers to lead the investigation and critical examination of these tools.

The reliability and accuracy of responses generated by LLMs hinge upon the quality of data they have been trained on. Constrained by the scope of their training corpus, these models may inadvertently perpetuate biases inherent in the data. As such, it becomes crucial for humanities researchers to scrutinize these tools and explore avenues for integrating them into our research. It is worth noting that humans, too, are influenced by the data on which we are "trained," such as our memories and knowledge, and are therefore subject to our own biases. Possessing expertise in untangling such complexities, we are well-suited to tackle this challenge.

#### Text Generation

The present report contains text that was written with the assistance of OpenAI\'s models. Though some may find this decision controversial, I firmly believe that the text generated by these models is just as much my own as anything I could have written manually. Writing a research paper is not a linear process, but rather a constant cycle of drafting, re-reading, re-writing, and revising until the desired outcome is achieved. During this process, I leveraged a variety of resources, including LLMs, to improve my writing, develop my ideas, and save time for tasks that require human expertise.

While I have used LLMs to generate specific passages, it is essential to recognise that these passages have undergone significant revision and are tailored to my iterative writing process. This approach involves several rounds of editing, revising, and re-reading, meaning that any text generated by LLMs is subjected to extensive scrutiny and, where necessary, manual refinement.

In addition to generating text contained within this report, LLMs were also used to refine and collect my loose notes from the interviews. In Appendix X, you can see examples of this process.

#### New Challenges Presented by Working with LLMs

While LLMs have proven to be highly beneficial, utilising these models does not simply reduce the workload; rather, it shifts the workload onto a different set of competencies. The quality of results obtained from an LLM is heavily dependent on the effectiveness of human communication with the model, giving rise to the art of prompt engineering. Prompt engineering refers to the process of crafting prompts or instructions that guide LLMs in producing high-quality results.

In contrast to their predecessors, GPT-3.5 and GPT-4 do not currently support fine-tuning, which makes prompt engineering even more critical. Without the ability to fine-tune the model for specific tasks, the design of the prompt becomes essential in obtaining high-quality results.

The prompt engineering process involves several steps, including selecting appropriate text prompts, tuning the model\'s hyperparameters (such as temperature, which governs the level of creativity or novelty in the output), and tailoring the prompt design to the model\'s capabilities. The primary goal is to create prompts that provide sufficient context for the model to generate high-quality results while avoiding those that may lead to incorrect or irrelevant outputs.

For instance, in the case of text summarisation, an effective prompt should encapsulate the main idea of the input text and supply enough information for the model to generate a concise summary. Similarly, in question-answering tasks, a well-crafted prompt should capture the essence of the question and offer ample context for the model to generate accurate and relevant responses.

#### Platforms Used

Throughout my research, I aimed to find the most effective way to interact with large language models (LLMs). I began with ChatGPT, the well-known platform offering access to GPT-3.5 and limited access to GPT-4. However, I encountered several limitations that constrained my research.

Seeking a better approach, I experimented with OpenAI\'s developer playground. This platform allowed me to harness GPT-4\'s 8,000-token capacity and actively guide the model\'s responses by editing outputs, adjusting hyperparameters, and modifying the system prompt to adopt specific roles, such as an ethnographer. Despite these advantages, the developer playground lacked a user-friendly method for saving and referencing chats.

My search led me to the GitHub project \"Chat with GPT," (Cogent Apps et al. n.d.) which provided an efficient and intuitive interface for engaging with LLMs. This platform facilitated access to LLMs through an API key and featured a built-in search function, streamlining the navigation and retrieval of specific conversations.

Using the \"Chat with GPT\" platform, I effectively incorporated LLMs like GPT-4 into my research, allowing me to explore their strengths and weaknesses within the context of the present study. Although GPT-4 offers a more powerful 32,000-token variant, I did not have access to it during my research.

#### Affinity Diagraming

After conducting the interviews and writing my detailed notes, I began the task of sifting through the data with the help of affinity diagrams. In the following sections, I will detail how I went about doing this.

#### Manual Affinity Digram Creation

To create an affinity diagram, I followed a structured process that began with the analysis of the qualitative data collected from the semi-structured interviews. The process involved the following steps:

1.  Data segmentation: I divided the interview notes into discrete statements or observations, each representing a single idea or insight expressed by the interviewees.
2.  Sorting and grouping: I sorted the statements into groups based on their similarities and relationships. This process was iterative, with statements being moved between groups as new connections and patterns emerged.
3.  Labelling: Once the groups were formed, I assigned descriptive headings to each group, capturing the essence of the content within. These headings represented the primary themes and patterns identified in the data.
4.  Review and refinement: I reviewed the affinity diagram, ensuring that the groupings and labels accurately represented the data and making adjustments as needed.

#### Affinity Diagram Creation Assisted by GPT-4

In this section, I will explore the capabilities of GPT-4 in creating an affinity diagram and compare its performance with that of myself as a human ethnographer. Affinity diagrams are useful tools for organising and making sense of vast amounts of information. Given GPT-4\'s ability to process vast swaths of text, it presents a unique opportunity to investigate the effectiveness of the language model in creating a affinity diagrams.

Prompt engineering is an essential part of attaining high-quality results from large language models (LLMs) like GPT-4. In this section, I will focus on prompt engineering and its importance in achieving the desired output. However, I must also manage the workload of prompt engineering to prevent it from becoming more resource-intensive than manual labor.

However, GPT-4's improved ability to understand and assist with meta-tasks, such as improving upon its own prompts, presents a possible avenue for ensuring that utilising LLMs does not defeat itself in this way.

Rather than spending a long time crafting the perfect prompt, I opted for an iterative approach to prompt engineering, attempting several methods of eliciting affinity diagrams from GPT-4.

By exploring the capabilities of GPT-4 in creating an affinity diagram and comparing it to that of a human ethnographer, I seek to gain insights into the strengths and limitations of the language model in this task.

##### The Quick and Dirty Approach.
In my first attempt to get GPT-4 to produce an affinity diagram, I gave it the following prompt: \"You are an ethnographer who evaluates user inputs and creates affinity diagrams based on the narratives they contain. Your report should summarize the most prominent discourses, including references to specific interviewees where appropriate.\"

 GPT-4 provided an analysis of the interview data and generated its own affinity diagram, which identified themes and patterns in the data, followed by a summary of the most significant discourses. The output was technologically impressive, but some of the fundamental issues with large language models made it methodologically questionable.

 While GPT-4 was clearly familiar with the concept of an affinity diagram, its results were somewhat superficial, seeming to be based on a mere first impression of the data. The raw output is as follows:

> Affinity Diagram Themes:
>
> 1\. Understanding of the IT investment process
> 2\. Communication and collaboration with the IT department
> 3\. Challenges and frustrations in implementing new systems
> 4\. Suggestions for improvement
>
> Summary of Prominent Discourses:
> 1\. Many interviewees were not aware of the IT investment process or did not see the relevance to their work. For instance, Karina (Interview 165) did not think it was important for her role, while Anne (Interview 190) was not aware of the process before the interview.
>
> 2\. Communication and collaboration with the IT department were highlighted as crucial factors in the successful implementation of new systems. Lise (Interview 161) emphasized the need for understanding the specific context of daycare workers, while Peter (Interview 183) expressed concern about gaps in IT support at his residential care facility.
>
> 3\. Several interviewees described challenges and frustrations in implementing new systems, often due to a lack of communication and understanding between different departments or the IT department\'s perceived rigidity. Examples include Mikkel (Interview 169), who faced dilemmas when reconciling the municipality\'s network requirements with the library\'s separate organizational status, and Freja (Interview 189), who found the IT investment process bureaucratic and unhelpful.
>
> 4\. Suggestions for improvement included clearer communication about the IT investment process and its purpose, as well as more targeted promotion to specific departments that deal with IT investments. Emma (Interview 181) suggested changing the name of the process to make it more tangible, while Lise (Interview 161) proposed adding an option on the form to indicate if the case involves a target group with difficulty adapting to technological changes. Anne (Interview 190) suggested the development of a central system to direct communication based on guidelines, as well as establishing more fixed and transparent guidelines for reporting new investments within the organization.
>
> In conclusion, the most prominent discourses focused on the understanding and awareness of the IT investment process, the importance of communication and collaboration with the IT department, the challenges and frustrations experienced in implementing new systems, and suggestions for improving the process. Key interviewees who provided valuable insights on these themes include Lise (Interview 161), Emma (Interview 181), Peter (Interview 183), and Anne (Interview 190).

##### The Simulated-Thought Approach.
Large language models like GPT-4 do not think, but rather produce words (or, more correctly, tokens) one at a time based on their probability of appearing as the next word in the text (Mahowald et al. 2023; Brown et al. 2020; Gun et al. 2023). This in contrast to humans whose language and reasoning centers are contained within separate areas of the brain (Mahowald et al. 2023, Valmeekam et al. 2022). Nevertheless, researchers have noted significantly improved outcomes in reasoning tasks when models are prompted to produce a chain-of-thought (Wei et al. 2022; Richards et al. 2023; Wei, n.d.; Jsalsman, 2023). Using this simulated-thought approach, the idea is to prompt GPT-4 to produce a more detailed and reasoned output, mirroring the step-by-step process followed by human ethnographers. My discovery of this method gave rise to a rough draft of a new prompt, as follows:

> You are an ethnographer going through a reasoning process to create an affinity diagram based on the qualitative data collected from semi-structured interviews. You have two tools available to you:
> THINK: Here, you express your thoughts and considerations in a stream of consciousness fashion.
> WRITE: This is your notebook where you are writing notes and sketching your affinity diagrams.
> Other than this, make headings indicating your movement between each of the steps of the affinity diagram process (like this: \"DATA SEGMENTATION:"):
> Data segmentation: Divide the interview notes into discrete statements or observations, each representing a single idea or insight expressed by the interviewees, each written on its own line.
> Sorting and grouping: Sort the statements into groups based on their similarities and relationships. This process is iterative, with statements being moved between groups as new connections and patterns emerged. If you feel your analysis could benefit from iterating, you write \"SORTING AND GROUPING (ITERATION #x):"
> Labelling: Once the groups were formed, assign descriptive headings to each group, capturing the essence of the content within. These headings represent the primary themes and patterns identified in the data. Review and refinemeznt: Review the affinity diagram, ensuring that the groupings and labels accurately represented the data and making adjustments as needed.

The resulting analysis seemed to take a step back from the quick and dirty approach. However, the model's output succeeded to some degree in giving a clearer train of thought, making it easier to explain why the model responded as it did. The raw output is as follows:

> DATA SEGMENTATION:
> 1.  Lise as a \"link\" and \"translator\" between daycare workers and the Administration Building.
> 2.  Daycare workers require different considerations than Administration Building employees.
> 3.  Installing new apps on iPads can be confusing for daycare workers.
> 4.  Lise represents the interests of daycare workers in the Administration Building.
> 5.  Lise would be \"concerned\" and \"sad\" if she had to use a form to contact the IT department.
> 6.  Lise believes the ["]{dir="rtl"}unspoken considerations" that occur when contacting someone in the IT department personally would be lost if using a form.
> 7.  Emma believes that merging the IT investment process with their application template could be a great opportunity.
> 8.  Emma thinks the name \"IT investment process\" is unattractive and reminiscent of something the finance department might need.
> 9.  Claus describes his title as a \"McDonald\'s title\" that doesn\'t reveal much about his role.
> 10. Claus appreciates the ability to intervene if he feels a need has been misunderstood when using the IT investment process.
> 11. Peter feels that his dual role as IT support has sometimes compromised the well-being of the residents.
> 12. Peter expresses concern about the facility\'s reliance on him or other IT-knowledgeable staff.
> 13. Søren is responsible for purchasing IT equipment for schools.
> 14. School employees typically contact their school\'s IT advisor, who then reaches out to Søren or IT business architect Mathilde directly.
> 15. Søren believes it\'s realistic to get schools onboard with using the IT investment process, but it requires some \"training.\"
> 16. Anders provided valuable insights by discussing some IT investment projects and how the process looks in the real world from the perspective of someone not an insider in the IT department.
> 17. Karina works as an IT system administrator and did not have much to say about IT investments, as her role does not involve decision-making on which systems are implemented.
> 18. Mikkel works as a department head for the library\'s IT.
> 19. Mikkel\'s library has utilized the IT investment process.
> 20. Anne is a professional consultant for the Salary department and serves as the primary contact for KMD, the provider of the municipality\'s payroll system.

> SORTING AND GROUPING:
>
> Group 1: Role and responsibilities of interviewees
>
>> Lise as a \"link\" and \"translator\" between daycare workers and the Administration Building.
>
>> Emma works to implement new welfare technologies.
>
>> Claus is a development manager at CSV.
>
>> Peter works as a care assistant and helps with IT at the residential care facility.
>
>> Søren is responsible for purchasing IT equipment for schools.
>
>> Anders discussed IT investment projects from a non-IT department perspective.
>
>> Karina works as an IT system administrator.
>
>> Mikkel works as a department head for the library\'s IT.
>
>> Anne is a professional consultant for the Salary department.
>
> Group 2: IT investment process and its challenges
>
>> Lise would be \"concerned\" and \"sad\" if she had to use a form to contact the IT department.
>
>> Emma believes that merging the IT investment process with their application template could be a great opportunity.
>
>> Claus appreciates the ability to intervene if he feels a need has been misunderstood when using the IT investment process.
>
>> School employees typically contact their school\'s IT advisor instead of using the IT investment process.
>
>> Søren believes it\'s realistic to get schools onboard with using the IT investment process, but it requires some \"training.\"
>
>> Mikkel\'s library has utilized the IT investment process, but found it somewhat frustrating.
>
> Group 3: Communication and relationships with the IT department
>
>> Lise believes the ["]{dir="rtl"}unspoken considerations" that occur when contacting someone in the IT department personally would be lost if using a form.
>
>> Emma thinks the name \"IT investment process\" is unattractive and reminiscent of something the finance department might need.
>
>> Peter feels that his dual role as IT support has sometimes compromised the well-being of the residents.
>
>> Søren believes that the IT department should be better at using \"carrots\" rather than sticks.
>
>> Anders provided valuable insights by discussing some IT investment projects and how the process looks in the real world from the perspective of someone not an insider in the IT department.
>
>> Anne is responsible for ensuring that form 32 is completed for new systems that affect the payroll system.
>
> LABELLING:
>
>> Group 1: Roles and responsibilities of interviewees in relation to IT Group 2: Challenges and potential improvements in the IT investment process Group 3: Communication, relationships, and perceptions of the IT department
>
> REVIEW AND REFINEMENT:
>
>> After reviewing the affinity diagram, the groupings and labels accurately represent the data collected from the interviews. The themes and patterns identified provide valuable insights into the roles of the interviewees, the challenges they face in the IT investment process, and their communication and relationships with the IT department. No adjustments are needed at this time.

## Presentation of Data

### Interview Data


## Findings

## Discussion

## Alternative prompting methods for GPT affinity diagrams

## Conclusion

## References

## Appendices
