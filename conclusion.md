Write a conclusion to a masters thesis using the following information:
1.  A clear answer to your research question or hypothesis
There are two research questions. I will answer this for both of them:

### How does GPT-4's capacity to generate affinity diagrams from interview data compare to that of a human researcher, and what insights can this provide for qualitative research methodologies?
The depth of analysis fell short of what the human involved in interviewing and gathering data could do. For now, the results are lackluster, but with exciting opportunities for future research
### What are the key factors contributing to the non-compliance of employees with the IT investment process in Vejle municipality, and how can these factors be addressed to improve adherence?
Answer: The process is viewed as being very bureaucratic and the reward for particpating in the official process instead of just contacting known contact persons in the IT department are not obvious. Some interviewees expressed discomfort with needing to use such a process, fearing that consideration would not be taken to the sensitive nature of the employees daycare employees she works with. The text on Vejle Municipality's intranet for the IT investment process makes it seem excessively bureaucratic, not emphasising the benefits of using the process and instead focusing on mandates from the city council and the official guidelines for when to report. This could be improved by reconsidering how the IT investment process is communicated, letting more user-friendly text stand on the intranet page, putting the intricate reporting guidelines somewhere else. Telling what happens after users use the webform would be good, consoling worries about being sent to someone who doesn't necessarily understand intricacies of the work context. Perhaps giving an option to allow employees to choose a preferred contact in the IT department could help give a sense of safety. Setting an example, making an intranet site the IT architects could refer to as a resource for informing people about the process, and then actually promoting it when they get personally contacted about new investments saying, "it's okay this time, but next time use this process," sending a link to a user-friendly page– that is much more likely to be a success. Perhaps also changing the name IT investment process to something seeming more attractive could be a good idea, one of the interviewees suggesting "Indkøbsguiden" (in English, "The Purchase Guide")
3.  Summary of the main findings or argument

The interview data revealed that many people didn't know the IT investment process existed, and most of the interviewees had a view of it seeming bureaucratic and unappealing. The IT investment process has an awareness problem, as originally hypothesised by the IT architects, but it also has a serious image problem that should be addressed before starting larger scale promotion of the process, in order to increase the effectiveness of the efforts.

GPT-4 made a reasonable analysis within the confines of the data it was given, but it is clear that raw interview data alone is not enough to attain a deep analysis of the subject and hand. The direct prompting approach performed similarly to the Chain of Thought Approach, which is hypothesised to be a result of this (taken from the literature review, don't put so much detail, just reference):

>An emergent complexity both from the findings of this study and recent research conducted after the data collection phase of the present research centres on GPT-4's difficulty in simultaneously managing multiple instructions. Mirroring a human tendency to become overwhelmed when faced with numerous tasks at once, GPT-4's performance appears to decline under similar circumstances. This understanding might illuminate why the model struggled to deliver satisfactory results when tasked with both generating critiques and iterating upon them within a single, comprehensive prompt [@hebenstreit2023automatically; @shinn2023reflexion].

>A notable exemplification of this challenge can be seen in the self-critique prompt from @hebenstreit2023automatically. The model was instructed to "Answer the question, then critique the answer. Based on the critique, reconsider the other answer options and give a single final answer." Intriguingly, in this situation, GPT-4's performance was on par with direct prompting, where the question was asked with no additional directives. This result contrasts sharply with expectations given that the self-critique strategy has previously demonstrated efficacy in enhancing results in various contexts, as observed by @shinn2023reflexion.

If the task was broken up into multiple prompts and requests to the model, also employing the Chain of Thought Approach, it could show itself to be a po

5.  Connections between your findings or argument to other research
I enter as one of the first into the arena of investigating what LLMs are able to do in qualitative research. These are two pools of research that until now have mostly gone unjoined, as the technology until recently had not come far enough to be of actual use to qualtiative research. This is something that is changing very quickly in these times, and I can only urge future research to take these inqueries seriously and look further into it.
7.  Implications of the findings & Explanation and significance of the findings
While GPT-4's analysis was lackluster in its depth, this is a proof of concept that GPT-4 is indeed capable of yielding analyses based on relatively large amounts of qualitative data. In the opportunities for further research, I explain how I think my approaches could be built upon to yield even better results and results which I think might be surprising to the skeptical reader. These models have shown that they are able to do quite a bit given that they have the necessary information in the context of the conversation. Now, the further investigation will crux upon figuring out how one best can extract the context and subtext from the researcher's mind into the context of these language models.

While the affinity diagram is designed to be a quick and easy data analysis type and would be easily carried out by a human, this a proof of concept that these analyses are possible and that further investigation is warranted into how this could be practically used in research contexts. A promising area is using the models as a spring board to help the researcher reflect deeper on the data, getting external perspective from a model trained on a much larger dataset than any human could read in a life time, on the collected data without needing to inconvenience a colleague. Being able to quickly reference such a large corpus of text data could in the future (withholden ethical and factual concerns) help us researchers do more of the human things that we are good at, allocating more of the text-manipulating and analysis to machines.

These findings call indeed into question what it even means to be human, and I think this is an area where humanists need to go on the forefront, asking the questions of, what is our function as human researchers, what will it be going forward, what parts of our work can be replaced by complex algorithms and which parts of our work are important to have human participation and surveillance?

It is clear that qualitative analysis can in some degree or another be aided by large language models, but it is at the same time also clear that the language models are not ready to replace us yet. However, I think that this is more a model of programming and prompt engineering and less one of technological innovation than one would think. As shown in works of the like of @wei2022emergent, @hebenstreit2023automatically, and @shinn2023reflexion, language models are often, with proper support and prompting, capable of much more than they appear to be at the beginning. I believe that we have only seen the infancy of what these models will be able to do.

9.  Limitations of the research and methodology
As a master's thesis, the present research had funds limited by my personal funds. Research with more funds would be able to afford to be more experimental and iterate more on the prompt design than I was able to in the present research. With the prompt engineering here, I took a lot of exploratory approaches, and more focused studies in this area are needed.

As discussed in the recommendations for further research, I didn't do a full on EM investigation. A full-scale EM investigation would result in a more in-depth knowledge of what is going on in Vejle Municipality.
10.  Recommendations for future research
### Opportunities for Future Research for Research Question nr 1
#### Instruction Overload and the Role of Interaction
Addressing the challenge identified in this study, future research could experiment with streamlining each request made to the model. The complexities of juggling multiple tasks simultaneously – as observed in this study – might have imposed cognitive strain on GPT-4, impacting its performance. This theory aligns with the emergent findings from recent research into GPT-4's capabilities, such as those discussed in the "Effects of Simultaneous Instruction Overload on GPT-4 Performance" section of this study [@hebenstreit2023automatically; @shinn2023reflexion].

In future work, we might explore the efficacy of dividing tasks among several requests to GPT-4 rather than bundling them into one. By separating tasks like data segmentation and grouping, and possibly also lowering the demand for data segments from fifty to a more manageable number, we may help the model avoid performance degradation. This separation of tasks could also offer a significant additional benefit: it would enable the researcher to interactively shape the analysis, refining the model's outputs and guiding its future directions based on each output it generates. 

This interactive approach acknowledges the model's ability to learn from conversational context, harnessing it for a more precise analysis. It allows for a form of dialogue between the researcher and the model, with the researcher being able to modify the model's outputs in the ongoing conversation to better align with the research objectives.

These research avenues underscore the significance of understanding the limitations of GPT-4, and the importance of devising strategies that work within these constraints to extract optimal performance. This includes harnessing the potential of a more interactive relationship with the model, guiding it towards more accurate and relevant outputs. Through these strategies, we may enhance the utility of AI in qualitative data analysis.


#### LLM-Assisted Socratic Elucidation
Future research could further explore the interactive dialogue-based approach, which could be termed as "LLM-Assisted Socratic Elucidation" or "SocElu". The SocElu approach involves the researcher engaging in a step-by-step dialogue with GPT-4, guiding the model's analysis through a Socratic method of questioning. Notably, this approach could address one of the key limitations of current large language models, namely their lack of inherent knowledge about specific organizational contexts.

In the SocElu approach, the roles are somewhat reversed: the model is prompted to ask thought-provoking questions to the researcher. The researcher answers these queries, providing the model with additional context, clarifying ambiguities, and rectifying misconceptions. Based on these responses, the model formulates more questions, creating an iterative dialogue process. This cycle continues until the researcher determines that they have provided sufficient information for the model to understand the data in its specific organisational context.

The researcher's feedback and the iterative dialogue process could help the model develop a more nuanced understanding of the organisational dynamics at play. Consequently, the model could generate a more accurate and contextually aware analysis, enhancing the relevance, completeness, and utility of its output.

The LLM-Assisted Socratic Elucidation approach opens up exciting opportunities for future research in AI-assisted data analysis. By improving the model's contextual understanding and providing real-time feedback, this method holds promise for mitigating some of the challenges identified in this study. It presents an intriguing pathway towards enhancing the quality of large language model outputs in the realm of qualitative data analysis.

#### Improvements to the Bicameral Dialogue Approach
A promising development for the bicameral dialogue model involves the automatic generation of a council of diverse viewpoints, each representing various professional areas of expertise. By simulating a debate or panel discussion amongst these diverse experts, the model could explore topics from multiple angles, engage in rigorous debates, and generate a more balanced and comprehensive analysis. Each council member could represent a different discipline or area of knowledge, such as a scientist, philosopher, historian, or economist. Their interactions would offer a multifaceted examination of the topic at hand, enriching the dialogue by drawing from a broad range of expert perspectives. This approach could greatly expand the depth and breadth of the dialogue, allowing the model to tackle complex topics in a more holistic and intellectually rigorous manner.

Additionally, a moderator role could be incorporated to further enhance the dialogue's dynamism. Acting as a facilitator or critical thinker, the moderator would introduce thought-provoking questions, provide alternative perspectives, or introduce new information to stimulate deeper discussions. The moderator's role would be to challenge the council members, encouraging them to think critically, explore different angles, and delve into more complex aspects of the subject under discussion.

In terms of iterative model refinement, user feedback could be instrumental in improving the bicameral dialogue approach. Users could evaluate the quality, relevance, and coherence of the dialogue. This feedback, once collected and analysed, could fine-tune the model to better meet user expectations and preferences. This iterative process would help improve the model's performance, address biases or shortcomings, and enhance overall effectiveness and user satisfaction with the dialogue.

These enhancements address some of the limitations observed in previous applications of the bicameral dialogue model. For instance, our study found that the two 'selves' of the model often fell into a pattern of simply affirming one another's responses with short, confirmatory statements. While this maintained the flow of the dialogue, it did not substantively contribute to the depth or complexity of the conversation. By assigning contrasting roles to the 'selves' in the conversation and introducing a council of diverse viewpoints, future applications of this model could foster a more dynamic, engaged, and expansive dialogue.

### Opportunities for Future Research for research question 2
Further research is necessary to delve deeper into the facets of the IT investment process that weren't covered in depth during this study. Potential areas of exploration could include:

#### Comprehensive Review of Practices in Other Municipalities
In this study, we primarily focused on examining the IT practices within the Vejle municipality. However, our observations were limited to this area, leaving a gap in our understanding of how other municipalities manage new IT investments. Future research should cast a wider net, scrutinizing practices in various municipalities to identify the most effective strategies for managing IT investments. This approach can pave the way to establishing a standard for best practices among municipalities.

There's merit in drawing comparisons and lessons from the private sector, despite fundamental differences between it and the public sector. Mid to large-sized private companies may face similar challenges to Vejle's IT department, thus it's worthwhile to include such entities in future investigations.

To extend our exploration to other municipalities, leveraging established relationships between Vejle and its counterparts, such as Aarhus, Odense, Fredericia, Sønderborg, among others, would be advantageous.

#### Enhancing IT Investment Process Understanding Through Managerial Science
While the present research employs ethnographic methods to delve into IT investment process challenges primarily from a user standpoint, integrating insights from communication and managerial science could be highly valuable. These insights could guide the creation of custom communication strategies and action plans.

By incorporating managerial science principles, we could systematically investigate the decision-making processes, resource distribution, and performance metrics that shape the IT investment process in Vejle Municipality. This strategy would aid in pinpointing inefficiencies, discrepancies in incentives, and other potential hindrances to efficient IT investment management.

Communication specialists can play a crucial role in crafting targeted communication plans. Their expertise can guide the choice of effective ways to share information, encourage cooperation, and foster a culture of transparency and accountability. These experts can detect potential communication voids and propose strategies to fill them, ensuring all stakeholders are aware of their roles, responsibilities, and the overarching goals of the IT investment process.

An interdisciplinary approach that merges these ethnographic findings with insights from managerial science and communication expertise can yield a broader understanding of the IT investment process's issues. This comprehensive view can help identify key influences on employee behaviour and organisational culture, thereby informing the design of evidence-based interventions to enhance the IT investment process within the municipality.

#### In-Depth Exploration of IT Investment Process through Ethnomethodology
Drawing from the ethnographic approach that was undertaken in the current research, there are clear opportunities for further exploration, especially employing an EM approach. 

Future research can aim to delve deeper into the nuanced practices and interactions that constitute the IT investment processes. The daily workings of IT architects, as well as their decision-making processes, can be the focus of such studies. EM techniques, such as video analysis or conversational analysis, would be extremely useful for this purpose. This approach will help uncover not only the explicit knowledge that IT architects use when making IT investment decisions but also tacit knowledge and practices, which are often overlooked but are critical to the process and which potentially could benefit from being explicated.

Moreover, breaching experiments, another EM method, could provide valuable insights into the inherent assumptions and norms within the IT department and the larger organisation. These experiments involve intentionally breaking the "rules" of social behaviour to reveal underlying norms and expectations. In an IT investment context, this might involve changing certain standard procedures or channels of communication and observing how IT architects and other stakeholders react and adapt to these changes.

In addition, a more detailed study of the social interactions and meaning-making processes associated with IT investments could be beneficial. For instance, how do different stakeholders negotiate and collaborate during the IT investment process? What kinds of informal communication and collaboration channels exist? And how do these processes influence IT investment decisions?

Finally, more research could be done on how sociocultural factors impact the IT investment process. The EM approach could be particularly effective in uncovering these influences, as it emphasises the importance of social context in shaping behaviours and actions.

In summary, the current research has laid the groundwork for a more detailed exploration of the IT investment process. Future studies that incorporate EM methods could build on this foundation, providing a more holistic and in-depth understanding of the complex social dynamics that underlie IT investments. These studies could in turn inform more effective strategies and interventions for improving IT investment processes within municipalities and other organisational contexts.